<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Scorpio</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="Scorpio">
<meta property="og:url" content="http://leotse90.com/page/4/index.html">
<meta property="og:site_name" content="Scorpio">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Scorpio">
<meta name="twitter:description">
  
    <link rel="alternative" href="/atom.xml" title="Scorpio" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  

</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Scorpio</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">My name is L.T.</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://leotse90.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Python任务调度队列Celery" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/09/29/Python任务调度队列Celery/" class="article-date">
  <time datetime="2015-09-29T07:50:40.000Z" itemprop="datePublished">2015-09-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Python任务调度队列Celery">Python任务调度队列Celery</h1><p><em>BY:leotse</em></p>
<h2 id="Introduction">Introduction</h2><p>在Python的使用过程中，我们常常会遇到执行一些多进程任务，或者一系列长时间的后台任务。比如，多进程下载视频并上传到某一个文件系统中。这时候，我们可以使用任务调度队列帮我们进行任务的分发与管理。</p>
<p>Celery就是这样一个任务队列，易于使用，入门简单。Celery常常需要第三方作为发送和接收消息的中间层，一般我们用到的有RabbitMQ、Redis、MongoDB等等，次等的选择也可以是数据库。</p>
<p>一般推荐使用RabbitMQ，但是我们这里用到Redis，因为Redis安装的时候依赖少，而且性能稳定，但是Redis也有缺点，那就是断电的时候会丢失数据。我们在这里，就以Redis作为Celery的第三方中间层。</p>
<h2 id="Installation">Installation</h2><p>我们这里使用Celery+redis套餐进行任务的调度。  </p>
<p>Celery的安装非常简单，在linux系统下直接执行：<br><code>sudo pip install Celery</code><br><code>sudo pip install celery-with-redis</code><br>如果上述安装失败，可以尝试：<br><code>sudo easy_install Celery</code>   </p>
<p>我们来验证一下Celery是否安装成功，进入python shell，输入：<br><code>from celery import Celery</code><br>如果没有报错，则说明安装成功。</p>
<p>接着我们安装redis：<br><code>sudo apt-get install redis-server</code><br>安装完成后，redis会自动启动，我们也来验证一下redis是否安装成功：<br><code>ps -aux|grep redis</code><br>如果看到以下输出，则说明安装ok：<br><code>redis      942  0.2  0.0  73852  1832 ?        Ssl  Apr13 302:26 /usr/bin/redis-server /etc/redis/redis.conf</code></p>
<p>它们的安装都比较简单。接下来我们看如何使用Celery进行任务调度。</p>
<h2 id="Usage">Usage</h2><p>我们应该都知道生产者-消费者模型，在使用Celery的时候，我们也需要一个生产者和一个消费者，生产者负责往队列里写入待处理的数据，消费者负责将数据从队列中取出并进行处理。我们在这里将redis作为存储这种“数据”的地方。</p>
<p>我们来看这样一个示例，我们假设要下载一批视频v1，v2，v3….，这批视频列表存在另一个文件系统中，我们假设通过get_video_list方法来获取这批视频列表，另一方面，我们可以通过download_video_worker(video)来下载视频。</p>
<p>那么，生产者的伪代码如下：</p>
<p><pre><code><br>import download_video_worker<br>video_list = get_video_list()<br>for video in video_list:<br>    download_video_worker.apply_async([video])<br></code></pre></p>
<p>消费者的伪代码如下： </p>
<p><pre><code><br>download_app=Celery(“download_videos”, broker=”redis://localhost:6379/0”)<br>@download_app.task`<br>def download_video_worker(video):<br>    download_video_to_local(video)<br></code></pre></p>
<p>接着我们运行Celery：<br><code>celery -A download_video_worker worker --loglevel=info</code>  </p>
<p>这样，当我们每次往队列中放入video信息时，celery就会执行download_video_woker中的逻辑处理video的下载过程。</p>
<h3 id="推荐阅读">推荐阅读</h3><p><a href="http://www.celeryproject.org/" target="_blank" rel="external">Homepage - Celery: Distributed Task Queue</a><br><a href="https://denibertovic.com/posts/celery-best-practices/" target="_blank" rel="external">CELERY - BEST PRACTICES</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://leotse90.com/2015/09/29/Python任务调度队列Celery/" data-id="cifz2w9760006u2s6iqxhmxwu" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hive浮点数比较与计算" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/09/29/Hive浮点数比较与计算/" class="article-date">
  <time datetime="2015-09-29T07:50:05.000Z" itemprop="datePublished">2015-09-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Hive浮点数比较与计算">Hive浮点数比较与计算</h1><p><strong>author:leotse</strong></p>
<h3 id="Hive浮点数比较">Hive浮点数比较</h3><p>Hive的较早前版本（0.9.0）在比较浮点数时会出现问题，如下：<br><code>hive&gt; select * from float_compare where weight&gt;120.9;</code><br><code>OK</code><br><code>xiefeng 128.2</code><br><code>yolovon 121.8</code><br><code>leotse 120.9</code><br>我们可以看到，leotse乱入了，他的weight等于120.9，这一点与我们的预期不符合。设想一下，如果这些数据不是weight而是money，那么结果就会变成后果。这是Hive的一个BUG，我们在Hive的issues上可以看到<a href="https://issues.apache.org/jira/browse/HIVE-2586" target="_blank" rel="external">Float comparison doesn’t work</a>。这个问题已经解决了，但是我们仍然可以分析一下其他的原因。</p>
<p>在float_weight表中，weight以float类型保存。当我们在HiveQL语句输入120.9时，Hive会将其保存为double类型，这样我们看看120.9分别在这两种类型的表示：<br><code>float 120.9000001</code><br><code>double 120.900000000001</code><br>我们知道，在比较float和double类型数值时，float会强制转型为double。这样当float_compare表中数值120.9在和HQL中120.9比较时，前者会转型为120.900000100000。我们可以看到120.900000100000&gt;120.900000000001。这也就是为什么leotse会出现在查询结果的原因。</p>
<p>虽然这个问题已经解决，但是仍然给我们一些启示，当我们在进行浮点数比较的时候，需要警惕float和double的自动转型，特别需要避免从窄类型数值向宽类型数值的转型。</p>
<h3 id="Hive浮点数计算">Hive浮点数计算</h3><p>相比上面的问题，浮点数的计算也是一个BUG，而且现在还没有解决，<a href="https://issues.apache.org/jira/browse/HIVE-3715" target="_blank" rel="external">float and double calculation is inaccurate in Hive</a>。</p>
<p>为了方便对比，我们先展示出表float_compare中的全部数据：<br><code>hive&gt; select * from float_compare;</code><br><code>OK</code><br><code>dooley 110.0</code><br><code>xiefeng 128.2</code><br><code>leotse    120.9</code><br><code>februus 119.0</code><br><code>yolovon 121.8</code>  </p>
<p>接下来我们将表中的weight的字段除以10，得到如下结果：<br><code>hive&gt; select weight/10 from float_compare;</code><br><code>OK</code><br><code>11.0</code><br><code>12.819999694824219</code><br><code>12.09000015258789</code><br><code>11.9</code><br><code>12.180000305175781</code>  </p>
<p>我们可以看到，除了110.0和120.0这种小数点后为0的，其他浮点数计算的结果都是不符合我们预期的。实际上，这个问题在Hive和Java中都存在（Hive用Java实现），而且所有使用IEEE标准进行浮点数编码的系统都存在这个问题。目前这个没有被解决，在这里摆出来是希望以后在遇到类似的浮点数计算的时候，我们能够长一个心眼，以免出现了谬误还不知道为什么。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://leotse90.com/2015/09/29/Hive浮点数比较与计算/" data-id="cifz2w97c0009u2s6az0867s0" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hive之JOIN操作" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/09/29/Hive之JOIN操作/" class="article-date">
  <time datetime="2015-09-29T07:49:41.000Z" itemprop="datePublished">2015-09-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Hive之JOIN操作">Hive之JOIN操作</h1><p><em>整理：leotse</em></p>
<h3 id="Introduction">Introduction</h3><p>在MySQL等关系型数据库中，我们经常会用到联表查询，用以查询多张表的数据。<br>使用联表查询的场景一般是：我们需要对两张或多张表中的数据进行关联，从而得到我们所需要的数据集。  </p>
<p>在Hive中，也存在这样的场景，特别是进行数据分析的时候，但是，Hive虽然支持Hive JOIN语句，但是<strong>只限于等值连接</strong>，也就是说，只支持a.col=b.col而不支持a.col &gt;= b.col这类的条件，主要原因是通过MapReduce很难实现这种类型的联接。</p>
<p>接下来，我们将分析和介绍Hive中主要的JOIN操作。</p>
<p>我们假定我们有两张表：human和assets。它们分别记录了人口以及资产信息，它们的字段如下：<br><code>hive&gt; describe human;</code><br><code>OK</code><br><code>name                    string</code><br><code>age                     int</code><br><code>job                     string</code><br><code>addr                    string</code>  </p>
<p><code>hive&gt; describe assets;</code><br><code>OK</code><br><code>name                    string</code><br><code>bank                    string</code><br><code>fund                    int</code>  </p>
<p>在下面的例子中，将会用到这两张表。</p>
<h3 id="INNER_JOIN">INNER JOIN</h3><p>INNER JOIN，又称内连接。是较为常见的一种JOIN操作：<br><strong>Input</strong>: 表A、表B<br><strong>Condition</strong>: A.col = B.col<br><strong>Output</strong>: 表A和表B中满足Condition的所有数据记录<br><strong>Example</strong>:<br><code>SELECT a.col1, a.col2, b.col2, b.col3</code><br><code>FROM A a JOIN B b</code><br><code>ON a.col1 = b.col1</code><br><code>WHERE a.col3 = &#39;CONDITION&#39;;</code>  </p>
<p>我们来看一个具体的例子，我们想知道human表中每一个人在不同银行的存款记录，我们可以用以下SQL语句进行查询：<br><code>SELECT h.name, h.age, h.job, a.bank, a.fund FROM human h JOIN assets a ON h.name=a.name;</code><br>ON关键字指定了两种表联接的条件，<br>我们对输出结果进行了截取，只选取最终的数据查询记录，如下：<br><code>xiefeng    24    big data    CMB    15000000</code><br><code>leotse    25    programmer    CMB    200000000</code><br><code>leotse    25    programmer    CAB    10000000</code><br><code>yolovon    26    CEO    HB    5000000</code><br><code>yolovon    26    CEO    CCB    3200000</code>  </p>
<p>另外，我们需要注意的是，在Hive中，ON子句中尚不支持谓词OR。</p>
<p>如果我们对多表进行INNER JOIN操作，如:<br><code>SELECT a.col1, a.col2, b.col4, c.col5 FROM a</code><br><code>JOIN b ON a.col1 = b.col2</code><br><code>JOIN c ON a.col2 = c.col3</code><br><code>WHERE CLAUSE;</code><br>大多数情况下，Hive会对每次JOIN操作启动一个MR Job，（在Hive中，SQL的执行是从左至右的）这上面这个SQL语句的执行过程中，首先启动一个MR Job对表a和表b进行一次JOIN操作，然后再启动另一个新的MR Job对表a和表c进行一次JOIN操作。<br>上面说到是大多数情况下，那种小部分的情况是指只要我们使用的ON后的条件（即连接键）一致的话，那就只会产生一个MR Job。</p>
<p>Hive还假定最后一张JOIN的表最大，从而先将前面的表先缓存起来，直到最后一张表才进行计算，因此为了防止内存消耗过大，我们应该尽量保证JOIN操作的表从左到右表大小递增。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://leotse90.com/2015/09/29/Hive之JOIN操作/" data-id="cifz2w97k000bu2s6u2o4ahze" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Hive本地模式" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/09/29/Hive本地模式/" class="article-date">
  <time datetime="2015-09-29T03:53:37.000Z" itemprop="datePublished">2015-09-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Hive_本地模式">Hive 本地模式</h1><p><strong>by:leotse</strong></p>
<p>我们都知道，Hive是通过将HiveQL转化为MR job进行数据查询和处理。当然，不是全部的HQL语句都需要转为MR，比如我们常见的：<br><code>SELECT * FROM access_log;</code><br>这时候，Hive Shell能很快地返回给我们结果，这是因为这里用到的是Hive的<strong>本地模式</strong>。<br>Hive查询耗时太长，一直都是大家吐槽的对象，在数据量大的情况下，当然微不足道，但是当我们的查询量很小亦即查询数据很少的时候，Hive启动的耗时将会显得非常刺眼，因此在0.7版本以后，Hive开始支持本地模式。</p>
<p>除了上面的示例使用到了本地模式，如果WHERE语句中只是分区字段这种情况，也是无需使用MR job的：<br><code>SELECT * FROM access_log</code><br><code>WHERE dt=&#39;20150916&#39;</code><br><code>LIMIT 10;</code><br>这是因为分区字段在HDFS中保存实际上是目录结构，这些都是不用通过计算获取的（包含LIMIT）。</p>
<p>除此之外，我们还可以怎么利用本地模式帮助我们快速处理少量数据呢？我们可以通过设置下面变量打开本地模式：<br><code>set hive.exec.mode.local.auto=true;</code><br>默认情况下这个设置为false，也就是说，Hive使用MR来执行其他的所有操作（区别上面介绍的两种）。</p>
<p>我们来感受下，下面截图为没有使用本地模式时查询数据条目数：<br><img src="https://github.com/leotse90/SparkNotes/blob/master/images/hive_local_mode_false.png" alt="hive_local_mode_false"><br>我们看到这个简单的操作用了34.321s，一共也就192条数据，这个固然和机器有关，但是MR启动以及计算导致时间成本太高。我们在下面的示例里打开了本地模式：<br><img src="https://github.com/leotse90/SparkNotes/blob/master/images/hive_local_mode_true.png" alt="hive_local_mode_true"><br>1.322s!，我们看到耗时明显降低，这就是本地模式的威力。</p>
<p>当然，使用本地模式也有一些条件：<br>1.<strong>输入数据的size</strong>：我们用参数hive.exec.mode.local.auto.inputbytes.max来指定本地模式处理的最大输入数据，默认为128MB；<br>2.<strong>Mapper的数量</strong>：参数hive.exec.mode.local.auto.tasks.max指定了本地模式下Mapper的最大数量，默认为4；<br>3.<strong>Reducer的数量</strong>：Reducer数量必须是0或1；</p>
<p>我们在使用Hive时，最好在$HOME/.hiverc配置文件中加入<code>set hive.exec.mode.local.auto=true;</code>设置。特别是当我们常常处理的数据量不大的时候！</p>
<p>另：由于Hadoop运行的机器和Hive client运行的机器可能环境不一致，JVM版本的不同或者软件的libs不同会导致本地模式可能出现不可预期的错误。另外一点值得我们注意的是，本地模式运行在Hive Client上一个独立的子JVM上，如果你愿意，那么你可以通过<code>hive.mapred.local.mem</code>参数来设置该子JVM最大内存，默认情况下，这个参数的值为0，在这种情况下，Hive会让Hadoop决定子JVM的默认内存限制。</p>
<p>参考：<br><a href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted#GettingStarted-Hive,Map-ReduceandLocal-Mode" target="_blank" rel="external">Hive GettingStarted</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://leotse90.com/2015/09/29/Hive本地模式/" data-id="cifz2w97i000au2s60r8evrbg" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/3/">&laquo; Prev</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/5/">Next &raquo;</a>
    </nav>
  
</section>
        
          <aside id="sidebar">
  
    
  
    
  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">十月 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">九月 2015</a><span class="archive-list-count">15</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2015/10/20/Scala入门/">(no title)</a>
          </li>
        
          <li>
            <a href="/2015/10/03/Hadoop安装之你不知道的事/">(no title)</a>
          </li>
        
          <li>
            <a href="/2015/09/29/MooseFS概览/">(no title)</a>
          </li>
        
          <li>
            <a href="/2015/09/29/【译】Python中yield关键字用法/">(no title)</a>
          </li>
        
          <li>
            <a href="/2015/09/29/改变FastDFS中某个机器的分组/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2015 Leo Tse<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>

  </div>
</body>
</html>